{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6be9b2f-7f45-4128-89a2-d8c52d2f43d3",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5053e16a-d772-4da3-ad82-561102503d9d",
   "metadata": {},
   "source": [
    "La pratique de l'aviron en milieu naturel, comme sur les fleuves et rivières, dépend fortement des conditions hydrologiques telles que le débit, la température extérieure ou la hauteur d'eau. Ces paramètres jouent un rôle crucial dans la sécurité des rameurs, la qualité de l'expérience sportive, et l'organisation des entraînements et des compétitions. \n",
    "\n",
    "La Fédération Française d'Aviron a donc émis des lignes directrices de sécurité, dont les principes sont généralement appliqués au sein des clubs français : les sorties sur les plans d'eaux sont interdites lorsque le débit est trop puissant. Les variations du débit, souvent influencées par les conditions météorologiques (pluies, sécheresses), rendent leur prévision essentielle pour les clubs d'aviron et leurs pratiquants. Ce projet, centré sur la Seine, vise donc à développer un modèle de prédiction des conditions de bassin : il permettra d'anticiper les jours où les conditions sont optimales pour la pratique de l'aviron et à l'inverse les jours où les sorties seront trop dangereuses, en se fondant sur des données hydrométriques et météorologiques. Ce travail combine une analyse des données historiques et actuelles, et fournira la base d'un outil fiable et pratique pour faciliter la planification dans les clubs d'aviron en facilitant le respect des normes de sécurité de la pratique sportive.\n",
    "\n",
    "Ce projet comprend 3 grandes parties : \n",
    "- Dans la première partie, nous importons les bases de données utiles\n",
    "- Dans la deuxième partie, nous étudions et analysons les données recueillies pour préparer le modèle prédictif\n",
    "- Dans la troisième partie, nous modélisons le problème pour tenter d'y apporter une réponse satisfaisante. Pour des questions de commodité et de rapidité d'exécution, nous avons choisi d'entraîner le modèle sur les données d'un peu plus d'un an (1er janvier 2023-30 novembre 2024).\n",
    "\n",
    "NB : les fonctions ont été rassemblées dans des scripts et n'apparaissent pas directement dans ce notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac5599c",
   "metadata": {},
   "source": [
    "# Sommaire\n",
    "<!-- TOC maxdepth:5 -->\n",
    "- [Introduction](#Introduction)\n",
    "- [Sommaire](#Sommaire)\n",
    "- [Environnement](#Environnement)\n",
    "- [Data Loading](#1-data-loading)\n",
    "  - [Bases de données météo horaire](#1-data-loading)\n",
    "  - [Bases de données des clubs d'aviron](#1-data-loading)\n",
    "  - [Clubs d'aviron et stations météorologiques et hydrologiques](#1-data-loading)\n",
    "  - [Bases de données hydrométriques horaire (Archives)](#1-data-loading)\n",
    "  - [Bases de données fluviales](#1-data-loading)\n",
    "- [Data Analysis](#2-data-analysis)\n",
    "  - [Représentation graphique](#21-représentation-graphique-des-fleuves-des-stations-météorologique-et-hydrométrique-et-des-clubs-daviron)\n",
    "  - [Précipitations en fonction du temps](#22-graphe-des-précipitations-en-fonction-du-temps)\n",
    "    - [Heure par heure](#22a-heure-par-heure)\n",
    "    - [Par semaine](#22b-par-semaine)\n",
    "  - [Températures en fonction du temps](#23-graphe-des-températures-en-fonction-du-temps)\n",
    "    - [Heure par heure](#23a-heure-par-heure)\n",
    "    - [Par semaine](#22b-par-semaine)\n",
    "  - [Débit en fonction du temps](#24-graphe-du-débit-en-fonction-du-temps)\n",
    "    - [Heure par heure](#24a-par-heure)\n",
    "    - [Par semaine](#24b-par-semaine)\n",
    "- [Data Modeling](#3-data-modeling)\n",
    "  - [Création du dataframe complet de modélisation](#31-création-du-dataframe-complet-de-modélisation-de-la-situation)\n",
    "  - [Etude approfondie de corrélation entre les variables](#32-etude-approfondie-de-corrélation-entre-les-variables)\n",
    "  - [Création du modèle](#33-création-du-modèle)\n",
    "  - [Prédiction](#34-prédiction)\n",
    "- [Conclusion](#conclusion)\n",
    "<!-- /TOC -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d3cc51",
   "metadata": {},
   "source": [
    "# Environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daaf3c3-d3f4-42cf-81b8-f38015bfb982",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cartopy\n",
    "!pip install geopy\n",
    "!pip install jupyter_contrib_nbextensions\n",
    "!pip install --upgrade xgboost\n",
    "!pip install --upgrade cffi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7d64eb-c848-4d9f-a943-197735bf86ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from IPython.display import Markdown, display\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from urllib.request import Request, urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6f1898-575f-4720-a3f1-604b778c29ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/onyxia/work/Projet-de-Python-Leroux-Gisserot\") # pour l'emplacement\n",
    "os.environ[\"PROJ_LIB\"] = \"/opt/conda/share/proj\" # pour les projections sur carte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5317ce-8fef-4963-812a-861cf14c8b09",
   "metadata": {},
   "source": [
    "# 1. Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e379dcfc-2bb0-4e55-ae60-c7195f47d03f",
   "metadata": {},
   "source": [
    "Dans cette partie, nous importons :\n",
    "- des bases de données météo horaire, classées par département (data.gouv.fr)\n",
    "- des bases de données concernant les archives du débit de la Seine, pour chaque station hydrométrique d'intérêt\n",
    "- une base de données permettant de tracer les cours d'eau sur une carte\n",
    "- une base de données permettant de localiser les clubs d'aviron\n",
    "- une base de données regroupant les informations des clubs d'aviron et des stations météorologique et hydrométriques les plus proches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa3d594-211b-44b7-8eeb-b4f6f6136607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des fonctions utiles pour cette partie\n",
    "from utils.data_loading import (\n",
    "    read_csv_from_url, \n",
    "    load_department_data,\n",
    "    load_and_save_all_department_data,\n",
    "    load_data_from_disk,\n",
    "    load_data_from_disk_hydro,\n",
    "    cleaning_and_organizing,\n",
    "    get_coordinates,\n",
    "    import_geojson_from_url,\n",
    "    find_nearest_station,\n",
    "    add_station_info_to_clubs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deb64c1-d6f8-4b14-bb66-db9910301d35",
   "metadata": {},
   "source": [
    "---\n",
    "### Bases de données météo horaire\n",
    "Téléchargement depuis météo france / data.gouv.fr des bases de données météo, puis concaténation et nettoyage. Nous nous sommes concentrés sur les départements dans lesquels passe la Seine afin d'obtenir les données météo des localisations proches des clubs d'aviron de long de la Seine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e063d0a9-faf2-43b1-8c72-7556ca34a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_and_save_all_department_data(\n",
    "    department_ids=[\"10\", \"27\", \"76\", \"77\", \"78\", \"91\", \"92\", \"95\"], # départements par lesquels passe la Seine\n",
    "    save_dir=\"/home/onyxia/work/Projet-de-Python-Leroux-Gisserot/data/hourly-weather-23-24\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af40c86-4a99-4630-9a1c-8ce5deb149cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_horaire = load_data_from_disk(data_dir=\"/home/onyxia/work/Projet-de-Python-Leroux-Gisserot/data/hourly-weather-23-24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57deb364-1e6b-40b2-9347-c41fda1f2b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_horaire = cleaning_and_organizing(\n",
    "                                df=meteo_horaire,\n",
    "                                columns=[\"DEPARTMENT_ID\", \"NOM_USUEL\", \"AAAAMMJJHH\"],\n",
    "                                date=\"AAAAMMJJHH\"\n",
    "                            )\n",
    "                            \n",
    "meteo_horaire                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79318092-9f52-49c5-8307-eea1b32c78fa",
   "metadata": {},
   "source": [
    "Le dataframe meteo_horaire contient les colonnes suivantes :\n",
    "- DEPARTMENT_ID : le numéro du département où se trouve la station météo considérée\n",
    "- NUM_POSTE : l'identifiant de la station météo\n",
    "- NOM_USUEL : le nom de la station météo\n",
    "- LAT et LON : les coordonnées de la station météo\n",
    "- AAAAMMJJHH : la date exacte, à l'heure près, de la collecte d'information\n",
    "- RR1 : les précipitations tombées en une heure (en millimètres)\n",
    "- T : la température moyenne enregistrée pendant cette heure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5b6f3f-f4f1-4d71-9d73-54f61c083427",
   "metadata": {},
   "source": [
    "On crée ensuite 2 dataframes différents:\n",
    "- l'un nous servira pour entraîner le modèle (données recueillies entre le 1er janvier 2023 et le 30 novembre 2024) : meteo_horaire_train\n",
    "- l'autre nous servira à faire des prédictions effectives (données recueillies sur les 30 derniers jours - durée maximale sur laquelle on dispose des données de débit en temps réel) : meteo_horaire_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad823e-591d-43f7-bc75-d6de88803a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_limite = pd.to_datetime(\"2024-12-01 00:00:00\")\n",
    "meteo_horaire_train = meteo_horaire[meteo_horaire['AAAAMMJJHH'] < date_limite]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb9705-0c3b-4d66-bfeb-015aa85d531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_ajd = pd.to_datetime(datetime.now())\n",
    "date_debut = date_ajd - timedelta(days=30)\n",
    "meteo_horaire_pred = meteo_horaire[(meteo_horaire['AAAAMMJJHH'] > date_debut) & (meteo_horaire['AAAAMMJJHH'] <= date_ajd)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c6a0e9-8b1e-47a0-ae96-e5c35f9faa8e",
   "metadata": {},
   "source": [
    "---\n",
    "### Base de données des clubs d'aviron et leur localisation\n",
    "\n",
    "Création du dataset à partir des noms des clubs et de leurs adresses (récupérées sur FFaviron.fr) et association avec leurs coordonnées GPS correspondantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3dd1ea-8b84-4eec-83d6-35cadaa2df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "clubs_aviron = pd.read_csv('/home/onyxia/work/Projet-de-Python-Leroux-Gisserot/data/adresses_clubs.csv', sep=';', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d31bc4-ee2c-4d7b-a2c8-3a850e6e370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clubs_aviron[['LAT', 'LON']] = clubs_aviron['Adresse'].apply(get_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e8f930-94f8-4212-8ee6-9ef1a4addfd7",
   "metadata": {},
   "source": [
    "---\n",
    "### Informations sur les clubs d'avirons, et les stations météorologiques et hydrologiques les plus proches\n",
    "\n",
    "Nous recensons les stations hydrométriques françaises grâce au dataset de l'Hydroportail hydro.eaufrance.fr, et le nettoyons de manière à ne garder que les colonnes d'intérêt pour les stations encore actives. On fait de même pour les stations météo, puis on merge les datasets afin d'obtenir un dataframe comprenant : les clubs d'aviron le long de la Seine, la station hydrométrique la plus proche sur la Seine (Nearest Hydro Station), la station météo la plus proche (Nearest Weather Station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd8f152-9693-4e46-a83e-eeb713e9b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recensement des stations hydrométriques françaises\n",
    "liste_stations_hydro = pd.read_csv('/home/onyxia/work/Projet-de-Python-Leroux-Gisserot/data/liste-stations.csv', sep=';', header=0)\n",
    "liste_stations_hydro = liste_stations_hydro.rename(columns={'cdentite': 'NUM_POSTE', 'lbstationhydro': 'NOM_USUEL', 'longitude': 'LON', 'latitude': 'LAT'})\n",
    "liste_stations_hydro = liste_stations_hydro[~liste_stations_hydro[\"dtfermeture\"].notna()] #Filtration des stations hydrométriques encore en activité\n",
    "liste_stations_hydro = liste_stations_hydro.drop(['typestation', 'dtmiseservice', 'dtfermeture'], axis=1) #liste des stations françaises avec les colonnes d'intérêt\n",
    "liste_stations_hydro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2526ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajout de la station météo la plus proche\n",
    "stations_meteo_clubs = add_station_info_to_clubs(clubs_aviron, meteo_horaire, filter_keyboard=None)\n",
    "stations_meteo_clubs = stations_meteo_clubs.rename(columns={'NUM_POSTE': 'NUM_NWS', 'NOM_USUEL': 'NWS'}) # NWS = Nearest Weather Station\n",
    "\n",
    "#Ajout de la station hydrométrique la plus proche\n",
    "stations_hydro_clubs = add_station_info_to_clubs(clubs_aviron, liste_stations_hydro, filter_keyboard='Seine') #Filtrer les stations prenant le débit de la Seine\n",
    "stations_hydro_clubs = stations_hydro_clubs.rename(columns={'NUM_POSTE': 'NUM_NHS', 'NOM_USUEL': 'NHS'}) # NHS = Nearest Hydro Station\n",
    "\n",
    "#Concaténation des dataframes.\n",
    "clubs_hydro_meteo = pd.merge(stations_meteo_clubs, stations_hydro_clubs, on=[\"Club\", \"Adresse\", \"LAT\", \"LON\"], how=\"inner\")\n",
    "clubs_hydro_meteo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc07c2c-f8a3-4f70-bbfa-beb2e7235f3c",
   "metadata": {},
   "source": [
    "---\n",
    "### Bases de données des archives hydrométriques\n",
    "\n",
    "Nous cherchons à obtenir les datasets d'historique des débits d'écoulement de l'eau aux stations hydrométriques heure par heure sur la période 01/01/2023-30/11/2023 (pour construire le futur dataset d'entrainement du modèle). Ils doivent être récupérés à la main sur le site hydro.eaufrance.fr à cause du fonctionnement du site. C'est ce que nous faisons ici : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e3861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Récupération des codes d'identification des stations les plus proches clubs d'aviron\n",
    "station_ids = clubs_hydro_meteo['NUM_NHS'].drop_duplicates().tolist()\n",
    "resultat = \"Les stations dont il faut récupérer les données dans les archives hydrométriques sont : \" + \", \".join(station_ids)\n",
    "display(Markdown(resultat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4432d9f4",
   "metadata": {},
   "source": [
    "On a donc téléchargé à la main les données des stations hydrométriques citées ci-dessus, et on les a placées dans le dossier hourly-flow-rate-23-24. Maintenant on les concatène, de manière à avoir un dataframe unique des débits aux stations hydrométriques considérées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ceca1a-6e56-4762-a9a9-f31c92a4c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement des données et association du code (NUM_POSTE) de la station dont elles sont issues\n",
    "debit_horaire = load_data_from_disk_hydro(data_dir=\"/home/onyxia/work/Projet-de-Python-Leroux-Gisserot/data/hourly-flow-rate-23-24\")\n",
    "\n",
    "#Normalisation du dataframe : Conversion de la date, suppression des colonnes inutiles, rename des colonnes\n",
    "debit_horaire['Date (TU)'] = pd.to_datetime(debit_horaire['Date (TU)'], utc=True).dt.tz_localize(None) \n",
    "debit_horaire = debit_horaire.drop(['Statut', 'Qualification', 'Méthode', 'Continuité'], axis=1) \n",
    "debit_horaire = debit_horaire.rename(columns={'Date (TU)': 'AAAAMMJJHH', 'Valeur (en m³/s)': 'debit'}) \n",
    "\n",
    "#Ajout du nom de la station hydro correspondante au code\n",
    "debit_horaire = debit_horaire.merge(liste_stations_hydro[['NUM_POSTE', 'NOM_USUEL']], on=\"NUM_POSTE\", how=\"left\")\n",
    "debit_horaire\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f4ca3f",
   "metadata": {},
   "source": [
    "---\n",
    "### Bases des données fluviales\n",
    "\n",
    "Importation directe des données fluviales françaises depuis data.gouv.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b60bccb-817b-4df7-a261-34e0670c6b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers = import_geojson_from_url(\n",
    "                geojson_url=\"https://www.data.gouv.fr/fr/datasets/r/f354a037-4a4e-4e7e-804b-01278ab228c5\",\n",
    "                geojson_file=\"/home/onyxia/work/Projet-de-Python-Leroux-Gisserot/data/rivers.geojson\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ef171-78c2-48f6-ae67-1901d1e5f279",
   "metadata": {},
   "source": [
    "# 2. Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385c50bb-5c8f-426c-b720-9d2196f799a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des fonctions utiles pour cette partie\n",
    "from utils.data_analysis import (\n",
    "    carte_figures,\n",
    "    trace_graphique,\n",
    "    trace_graphique_multiple,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3d5ab7",
   "metadata": {},
   "source": [
    "Cette partie vise à analyser les datasets que nous avons chargés, et à les mettre en perspective avec notre problématique de modélisation des variations du débit de la Seine. Nous commençons par une cartographie simple de notre cours d'eau d'étude :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b4fe7f-6dab-448c-94f4-73545b9bd50d",
   "metadata": {},
   "source": [
    "#### 2.1. Représentation graphique des fleuves, des stations météorologique et hydrométrique, et des clubs d'aviron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d19fe2b-c5e5-45cb-908c-9f3b9877d757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des coordonnées des stations meteo\n",
    "coord_ws = pd.merge(clubs_hydro_meteo, meteo_horaire, left_on='NUM_NWS', right_on='NUM_POSTE', how=\"inner\")\n",
    "coord_ws = coord_ws[[\"NUM_NWS\", \"NWS\", \"LAT_y\", \"LON_y\"]].drop_duplicates()\n",
    "coord_ws = coord_ws.rename(columns={'LAT_y': 'LAT', 'LON_y': 'LON'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70d97c-cb94-40e6-95b6-3c11d6a76a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des coordonnées des sttaions hydrométriques\n",
    "coord_hs = pd.merge(clubs_hydro_meteo, liste_stations_hydro, left_on='NUM_NHS', right_on='NUM_POSTE', how=\"inner\")\n",
    "coord_hs = coord_hs[[\"NUM_NHS\", \"NHS\", \"LAT_y\", \"LON_y\"]].drop_duplicates()\n",
    "coord_hs = coord_hs.rename(columns={'LAT_y': 'LAT', 'LON_y': 'LON'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd4fd1f-29db-48cb-b355-2f7121099840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracé du graphique\n",
    "carte_figures(rivers, coord_ws, coord_hs, clubs_aviron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13e85be",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d40a610-d75e-46c7-ad76-5a6787b7a3f2",
   "metadata": {},
   "source": [
    "On centre maintenant notre analyse sur un club d'aviron précis, l'Emulation nautique de Vernon, afin d'analyser les données que l'on a sur son bassin de pratique. Nous cherchons à tracer différents graphiques  (les précipitations, la température ou encore le débit en fonction du temps) pour tenter de remarquer des tendances ou des corrélations entres les variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c4623-d0e3-4338-b376-2e1d216b8d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_club = 'Emulation Nautique de Vernon'\n",
    "nws = clubs_hydro_meteo.loc[clubs_hydro_meteo['Club'] == nom_club, 'NWS'].iloc[0]\n",
    "nhs = clubs_hydro_meteo.loc[clubs_hydro_meteo['Club'] == nom_club, 'NHS'].iloc[0]\n",
    "nws_nhs = f'La station météo la plus proche du club {nom_club} est {nws} et la station hydrométrique la plus proche est {nhs}'\n",
    "display(Markdown(nws_nhs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb7df3f-565c-4fd7-9ba3-7a4e1d964253",
   "metadata": {},
   "source": [
    "#### 2.2 Graphe des précipitations en fonction du temps\n",
    "\n",
    "##### 2.2.a. <u>Heure par heure</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e4e5a-2564-4329-8225-0941fcee0c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création d'une copie du dataframe avec uniquement les précipitations et la température proches du club considéré\n",
    "meteo_nws = meteo_horaire[meteo_horaire[\"NOM_USUEL\"] == nws].copy()\n",
    "meteo_nws = meteo_nws.dropna(subset=['RR1', 'T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42057f8c-ef7d-45d2-bdf8-12e3873ad56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_graphique(\n",
    "    x=meteo_nws[\"AAAAMMJJHH\"],\n",
    "    y=meteo_nws[\"RR1\"],\n",
    "    titre=f\"Précipitations heure par heure pour le club {nom_club}\",\n",
    "    xlabel=\"Date (h)\",\n",
    "    ylabel=\"Précipitations (mm)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f5b88e-32c0-43b3-b34a-296b2ccdbe38",
   "metadata": {},
   "source": [
    "Ce graphique détaille les précipitations enregistrées **heure par heure**. Il met en évidence la nature très variable des précipitations, avec de nombreux pics irréguliers.  \n",
    "- Les pics isolés témoignent de périodes courtes mais **intenses de précipitation**.  \n",
    "- Entre ces pics, les précipitations sont souvent nulles ou très faibles.  \n",
    "\n",
    "Cette granularité **horaire**, utile pour analyser la variabilité des précipitations à court terme, rend difficile la lecture des **tendances globales** à cause de l'apparente saturation de l'information.\n",
    "\n",
    "Pour un modèle de prévision du débit, ces données brutes heure par heure peuvent donc être **trop détaillées** pour être directement exploitées. En effet, les débits d'un cours d'eau dépendent davantage de cumuls de précipitations sur des périodes plus longues (journées ou semaines) que d'événements ponctuels. Typiquement, de grosses averses (juillet-août 2024) sont plus plus susceptibles d'impacter le débit de la Seine que des pluies isolées, c'est ce qu'il serait intéressant d'étudier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75952575-e421-4b13-b705-3c36d29cfa2a",
   "metadata": {},
   "source": [
    "##### 2.2.b. <u>Par semaine</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd8ca45-6566-4362-978c-684eaff9575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée un nouveau dataframe où les précipitations sont sommées par semaine\n",
    "meteo_nws['hebdo'] = meteo_nws['AAAAMMJJHH'].dt.to_period('W')\n",
    "precipit_hebdo = meteo_nws.groupby('hebdo', as_index=False)['RR1'].sum()\n",
    "precipit_hebdo['hebdo'] = precipit_hebdo['hebdo'].dt.to_timestamp(how='start')\n",
    "\n",
    "# Puis on fait une moyenne glissante sur 3 semaines pour lisser la courbe\n",
    "precipit_hebdo['moy_gliss'] = precipit_hebdo['RR1'].rolling(window=3, min_periods=1, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44e7a58-6b79-41ba-ad49-0003b6391411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données pour la fonction\n",
    "y_dico1 = {\n",
    "    \"précipitations\": {\"y\": precipit_hebdo[\"RR1\"], \"color\": \"lightblue\", \"linestyle\": \"-\"},\n",
    "    \"précipitations lissées\": {\"y\": precipit_hebdo[\"moy_gliss\"], \"color\": \"red\", \"linestyle\": \"-\"}\n",
    "}\n",
    "\n",
    "# Appel de la fonction\n",
    "trace_graphique_multiple(\n",
    "    x=precipit_hebdo[\"hebdo\"],\n",
    "    y_mult=y_dico1,\n",
    "    titre=f'Tendance des précipitations par semaine pour le club {nom_club}',\n",
    "    xlabel=\"Semaine\",\n",
    "    ylabel=\"Précipitation (mm)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5718a5f-73ca-4610-80c8-a6133d9103fd",
   "metadata": {},
   "source": [
    "Ce graphique agrège les précipitations à une échelle **hebdomadaire**, ce qui permet de mieux identifier les **tendances globales** dans les précipitations :  \n",
    "- En bleu clair : la somme hebdomadaire des précipitations montre les fluctuations globales des précipitations au fil du temps.  \n",
    "- En rouge : la moyenne glissante sur 3 semaines lisse les variations hebdomadaires, révélant les tendances de fond sans être perturbée par des oscillations trop rapides.\n",
    "\n",
    "Ce lissage est particulièrement utile pour **détecter les périodes humides ou sèches prolongées**, qui influencent directement le débit des cours d'eau. On observe plusieurs pics significatifs sur l'année 2023 (notamment au printemps et en automne), ce qui est cohérent avec les périodes de précipitations accrues.  \n",
    "\n",
    "Les **sommations hebdomadaires** permettent de mieux **relier les précipitations aux variations de débit**, car elles intègrent une échelle temporelle plus pertinente pour l'évolution du niveau d'eau. La **moyenne glissante** aide à anticiper les périodes où les cours d'eau risquent d'atteindre des niveaux élevés, en réponse à des cumuls prolongés.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbcd39a-31ea-4e74-b6c4-3d54d83bd252",
   "metadata": {},
   "source": [
    "Pour **prédire le débit d'un cours d'eau**, il serait pertinent d'utiliser les données hebdomadaires comme **variable explicative principale**, en intégrant les tendances de fond issues de la moyenne glissante pour améliorer les prédictions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dd9704-ff00-4453-8af7-1808d4d04eb9",
   "metadata": {},
   "source": [
    "#### 2.3. Graphe des températures en fonction du temps\n",
    "##### 2.3.a. <u>Heure par heure</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ab56c3-31ff-4557-97ef-6b5a8d80c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_graphique(\n",
    "    x=meteo_nws[\"AAAAMMJJHH\"],\n",
    "    y=meteo_nws[\"T\"],\n",
    "    titre=f\"Températures heure par heure pour le club {nom_club}\",\n",
    "    xlabel=\"Date (h)\",\n",
    "    ylabel=\"Température (°C)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72535e4c-8746-43ec-a59d-a2c8325749e5",
   "metadata": {},
   "source": [
    "Ce graphique montre l'évolution de la température en fonction du temps à une résolution horaire. Il met à la fois en évidence les tendances globales de température en fonction des saisons (20-25°C vers juillet-août aussi bien en 2023 qu'en 2024, autour de 5°C en janvier-février) et la variabilité journalière des températures. Plusieurs phénomènes sont à analyser ici : d'abord la **saisonnalité temporelle** : les températures influencent l'évaporation et la fonte des neiges, ce qui peut expliquer un impact potentiel sur le débit des cours d'eau. Ensuite, la **variabilité horaire** est assez importante : cette variabilité peut être liée à des événements météorologiques locaux (comme des fronts froids ou chauds) qui affectent aussi les précipitations et, par extension, les débits des rivières.\n",
    "\n",
    "En conclusion : les températures, combinées aux précipitations, doivent logiquement influencer directement le débit par la fonte des neiges, l'infiltration dans les sols, et l'évaporation. Ces variations saisonnières et horaires de température doivent donc être intégrées comme une variable explicative dans le modèle de prédiction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723e0ed-83af-43e6-9866-3ccb203011ef",
   "metadata": {},
   "source": [
    "##### 2.3.b. <u>Par semaine</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67caeb7b-a160-4a56-9e34-88d69333051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On reproduit la même méthode que pour les précipitations\n",
    "temp_hebdo = meteo_nws.groupby('hebdo', as_index=False)['T'].mean()\n",
    "temp_hebdo['hebdo'] = temp_hebdo['hebdo'].dt.to_timestamp(how='start')\n",
    "temp_hebdo['moy_gliss'] = temp_hebdo['T'].rolling(window=3, min_periods=1, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ae5f4f-d94e-46b6-8e4c-8b0d4b507f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données pour la fonction\n",
    "y_dico2 = {\n",
    "    \"températures\": {\"y\": temp_hebdo[\"T\"], \"color\": \"lightblue\", \"linestyle\": \"-\"},\n",
    "    \"températures lissées\": {\"y\": temp_hebdo[\"moy_gliss\"], \"color\": \"red\", \"linestyle\": \"-\"}\n",
    "}\n",
    "\n",
    "# Appel de la fonction\n",
    "trace_graphique_multiple(\n",
    "    x=temp_hebdo[\"hebdo\"],\n",
    "    y_mult=y_dico2,\n",
    "    titre=f'Tendance des températures par semaine pour le club {nom_club}',\n",
    "    xlabel=\"Semaine\",\n",
    "    ylabel=\"Température (°C)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499453e1-4f77-4f0e-bcce-243b1bec2f67",
   "metadata": {},
   "source": [
    "Ici, on se restreint à la compréhension des tendances globales de températures. Cette restriction ne permet pas de voir de corrélation directe avec les précipitations. Les températures et les précipitations jouent donc probablement leur rôle dans la prédiction du débit des cours d'eau de manière indépendante.\n",
    "\n",
    "Mais on peut d'ores-et-déjà émettre quelques hypothèses : \n",
    "- plus les précipitations sont importantes et plus elles durent longtemps, plus le débit sera élevé, ceteris paribus\n",
    "- plus la température est élevée et plus la période de chaleur est longue, plus le débit sera faible, ceteris paribus\n",
    "- plus la température est élevée, plus les précipitations ont un impact positif sur le débit (par ruissellement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79979a7",
   "metadata": {},
   "source": [
    "----\n",
    "Mettons maintenant ces informations en perspective avec le données liées au débit. Ces variations conditionnent la pratique de l'aviron : au-dessus d'un certain seuil, il devient trop dangereux de sortir sur l'eau en bateau."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47d6266-670d-4c1c-9726-03f07b5f2108",
   "metadata": {},
   "source": [
    "#### 2.4. Graphe du débit en fonction du temps\n",
    "##### 2.4.a. <u>Par heure</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a888be-510f-4e1c-88fc-a51f7d3608bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création d'une copie du dataframe avec uniquement le débit capté au plus proche du club d'aviron considéré\n",
    "debit_nhs = debit_horaire[debit_horaire[\"NOM_USUEL\"] == nhs].copy()\n",
    "debit_nhs = debit_nhs.dropna(subset='debit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3841a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_graphique(\n",
    "    x=debit_nhs[\"AAAAMMJJHH\"],\n",
    "    y=debit_nhs[\"debit\"],\n",
    "    titre=f\"Débit heure par heure pour le club {nom_club}\",\n",
    "    xlabel=\"Date (h)\",\n",
    "    ylabel=\"Debit (en m³/s)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc7998c",
   "metadata": {},
   "source": [
    "De même que pour les autres variables, on observe des variations saisonnières marquées avec des pics de débit plus élevés au début de chaque année (notamment en hiver/printemps) et des périodes de débits plus faibles en été. Les variations sont relativement \"brutales\" lorsqu'elles surviennent, à contrario de la température où les écarts sont plus lissés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61bbbf1",
   "metadata": {},
   "source": [
    "##### 2.4.b. <u>Par semaine</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3488bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On reproduit la même méthode que pour les précipitations\n",
    "debit_nhs['hebdo'] = debit_nhs['AAAAMMJJHH'].dt.to_period('W')\n",
    "debit_hebdo = debit_nhs.groupby('hebdo', as_index=False)['debit'].mean()\n",
    "debit_hebdo['hebdo'] = debit_hebdo['hebdo'].dt.to_timestamp(how='start')\n",
    "debit_hebdo['moy_gliss'] = debit_hebdo['debit'].rolling(window=3, min_periods=1, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a8402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données pour la fonction\n",
    "y_dico2 = {\n",
    "    \"débit\": {\"y\": debit_hebdo[\"debit\"], \"color\": \"lightblue\", \"linestyle\": \"-\"},\n",
    "    \"débit lissé\": {\"y\": debit_hebdo[\"moy_gliss\"], \"color\": \"red\", \"linestyle\": \"-\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1066717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appel de la fonction\n",
    "trace_graphique_multiple(\n",
    "    x=debit_hebdo[\"hebdo\"],\n",
    "    y_mult=y_dico2,\n",
    "    titre=f'Tendance du débit par semaine pour le club {nom_club}',\n",
    "    xlabel=\"Semaine\",\n",
    "    ylabel=\"Débit (en m³/s)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3d10f8",
   "metadata": {},
   "source": [
    "Ce lissage met en évidence la tendance générale, en réduisant les variations hebdomadaires causées par des fluctuations très irrégulières (crues soudaines).\n",
    "Ce débit lissé suit la dynamique globale du débit réel mais élimine les pics et creux extrêmes, et permet de mieux voir les variations saisonnières. Par exemple, les hausses marquées du début de l’année (hiver/printemps) et les baisses durant l’été sont clairement visibles et plus facilement interprétables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8667df",
   "metadata": {},
   "source": [
    "# **3. Data modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a7a1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des fonctions utilisées dans cette partie\n",
    "from utils.data_modeling import (\n",
    "    correlation1,\n",
    "    correlation2,\n",
    "    plot_correlations,\n",
    "    create_features,\n",
    ")\n",
    "\n",
    "from utils.data_analysis import (trace_graphique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50366691",
   "metadata": {},
   "source": [
    "## 3.1 Création du dataframe complet de modélisation de la situation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff23edb4",
   "metadata": {},
   "source": [
    "On cherche à iobtenir un datagframe généraliste, regroupant toutes les données d'intérêt pré-chargées dans la partie data loading. C'est sur ce dataframe, regroupant toutes les donnée horaires par club d'aviron du 1 janvier 2023 au 30 novembre 2024 que nous entrainerons le modèle de prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5329d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1: on joint les données horaires hydrométriques avec celles des clubs,stations hydros et stations météo sur NUM_NHS\n",
    "debit_club = debit_horaire.merge(\n",
    "    clubs_hydro_meteo[['Club', 'LAT', 'LON', 'NUM_NHS', 'NHS']],\n",
    "    left_on='NUM_POSTE',\n",
    "    right_on='NUM_NHS',\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20eee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: on joint les données horaires météo avec avec celles des clubs,stations hydros et stations météo sur NUM_NWS\n",
    "meteo_club = meteo_horaire_train.merge(\n",
    "    clubs_hydro_meteo[['Club', 'LAT', 'LON', 'NUM_NWS', 'NWS']],\n",
    "    left_on='NUM_POSTE',\n",
    "    right_on='NUM_NWS',\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd0328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: on combine les deux DataFrames sur le Club et la colonne temporelle 'AAAAMJJHH'\n",
    "combined = debit_club.merge(\n",
    "    meteo_club,\n",
    "    on=['Club', 'AAAAMMJJHH'],\n",
    "    suffixes=('_hydro', '_meteo')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9e3ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: on sélectionne les colonnes pertinentes et on copie le dataframe pour éviter les intéractions fâcheuses\n",
    "result = combined[['Club', 'LAT', 'LON', 'NHS', 'NWS', 'AAAAMMJJHH', 'debit', 'RR1', 'T']].copy()\n",
    "\n",
    "# Et on normalise le dataframe afin de le rendre prêt pour la modélisation\n",
    "# On s'assure que toutes les valeurs sont numériques\n",
    "result[\"debit\"] = pd.to_numeric(result[\"debit\"], errors=\"coerce\")\n",
    "result[\"LAT\"] = pd.to_numeric(result[\"LAT\"], errors=\"coerce\")\n",
    "result[\"LON\"] = pd.to_numeric(result[\"LON\"], errors=\"coerce\")\n",
    "result = result.dropna(subset=[\"debit\", \"RR1\", \"T\"])\n",
    "\n",
    "# Suppression les colonnes inutiles pour la prédiction\n",
    "result = result.drop(columns=[\"NWS\", \"NHS\"])\n",
    "\n",
    "# Extraction les caractéristiques temporelles \n",
    "result[\"année\"] = result[\"AAAAMMJJHH\"].dt.year\n",
    "result[\"mois\"] = result[\"AAAAMMJJHH\"].dt.month\n",
    "result[\"jour\"] = result[\"AAAAMMJJHH\"].dt.day\n",
    "result[\"heure\"] = result[\"AAAAMMJJHH\"].dt.hour\n",
    "\n",
    "# Supprimer la colonne datetime originale si elle n'est plus utile\n",
    "result = result.drop(columns=[\"AAAAMMJJHH\"])\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77ef445",
   "metadata": {},
   "source": [
    "## 3.2 Etude approfondie de corrélation entre les variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f9c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrélation entre le débit et les précipitations aux heures précédentes\n",
    "correlation1(result, \"RR1\", 1, 26, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f869164",
   "metadata": {},
   "source": [
    "Les résultats montrent une très faible corrélation entre le débit et les précipitations aux heures précédentes, avec des coefficients proches de zéro, quelle que soit la période de décalage (1 à 25 heures). Cela suggère que les précipitations récentes ont peu ou pas d'impact direct et immédiat sur le débit mesuré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cca7fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrélation entre le débit et la température aux heures précédentes\n",
    "correlation1(result, \"T\", 1, 26, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1c4066",
   "metadata": {},
   "source": [
    "Les résultats montrent une corrélation négative faible entre le débit et la température, avec des valeurs autour de -0,19 pour tous les décalages. Cela signifie que la température a un effet légèrement inverse sur le débit, mais l’impact reste limité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a23e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrélation entre le débit et le débit aux heures précédentes\n",
    "correlation1(result, \"debit\", 1, 26, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43b8f7d",
   "metadata": {},
   "source": [
    "Il vient sans surprise que le débit à l'heure h est très corrélé (coefficient quasiment égal à 1) au débit aux heures h-1, h-2, etc. Inversement, celui-ci semble plutôt indépendant (coefficient faible voire presque nul) des précipitations ou des changements de température récents. \n",
    "\n",
    "Cependant disposer du débit de l'heure précédente n'est pas forcément très réaliste dans une optique de prédiction du débit d'un jour sur l'autre par exemple. On peut donc se concentrer sur l'étude de corrélation entre le débit et la moyenne des températures sur les derniers jours, ou entre le débit et la somme des précipitations sur les derniers jours.\n",
    "\n",
    "Nous cherchons à savoir à combien de jours il serait le plus efficace de remonter pour prédire le débit des jours à venir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3f841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrélation entre le débit et les précipitations sur une période donnée\n",
    "windows = list(range(24, 6*24+1, 24)) + list(range(7*24, 4*7*24+1, 7*24)) # on définit la fenêtre journalière\n",
    "correlations_RR1 = correlation2(result, column=\"RR1\", target=\"debit\", periods=windows)\n",
    "plot_correlations(correlations_RR1, title=\"Corrélation entre somme des précipitations et débit en fonction de la fenêtre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrélation entre le débit et la température sur une période donnée\n",
    "correlations_T = correlation2(result, column=\"T\", target=\"debit\", periods=windows)\n",
    "plot_correlations(correlations_T, title=\"Corrélation entre moyenne de température et débit en fonction de la fenêtre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cfdf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrélation entre le débit et la température sur une période donnée\n",
    "correlations_debit = correlation2(result, column=\"debit\", target=\"debit\", periods=windows)\n",
    "plot_correlations(correlations_debit, title=\"Corrélation entre moyenne du débit des jours précédents et débit en fonction de la fenêtre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4780c",
   "metadata": {},
   "source": [
    "Sous contrainte de données pour faire des prédictions effectives (30 jours) et par souci de réalisme, nous choisissons pour l'entraînement de retenir les données de débit du jour précédent, la moyenne des températures sur les 28 derniers jours et la somme des précipitations sur les 28 derniers jours également."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4594c4e",
   "metadata": {},
   "source": [
    "## 3.3 Création du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4b6956",
   "metadata": {},
   "source": [
    "Nous choisissons le modèle XGBRegressor, en le pensant particulièrement adapté pour des données complexes et des problèmes non linéaires, puisqu'il ne présuppose pas de relation linéaire entre les variables à prédire et les variables explicatives. Paramètres spécifiques utilisés : \n",
    "   \n",
    "-n_estimators=200 : un bon compromis entre performance et temps de calcul, permet de limiter le temps d'exécution et de rester relativement robuste\n",
    "   \n",
    "-learning_rate=0.1 : taux d'apprentissage assez faible, permet d'éviter le surapprentissage\n",
    "   \n",
    "-max_depth=15 : implique d'avoir des sous-modèles assez complexes mais aussi de gagner en précision,\n",
    "   \n",
    "-subsample=0.8 et colsample_bytree=0.8 : définissent la fraction des échantillons et des colonnes utilisées pour chaque arbre, paramètres assez standardisés\n",
    "   \n",
    "-random_state=42 : assure la reproductibilité des résultats, ce qui est essentiel pour valider la fiabilité de l'approche.\n",
    "\n",
    "-weigths sample : nous augmentons artificiellement énormément le poids de la latitude et de la longitude, puisque le débit dépend avant tout d'où sont situés les clubs.\n",
    "\n",
    "En combinant ces réglages, ce modèle permet d'équilibrer précision, vitesse d'apprentissage et généralisation, ce qui est crucial pour prédire des variables influencées par des facteurs environnementaux multiples comme c'est le cas ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8187a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des caractéristiques du modèle\n",
    "result_train = create_features(result).copy()\n",
    "\n",
    "# On supprime les lignes avec des valeurs manquantes dues aux décalages\n",
    "result_train = result_train.dropna()\n",
    "\n",
    "# Liste des variables explicatives\n",
    "liste_variables_explicatives = ['LAT', 'LON', 'RR1', 'T', 'année', 'mois', 'jour', 'heure', 'RR1_sum_4w', 'T_mean_4w', 'debit_mean_1d']\n",
    "\n",
    "# Définir les caractéristiques et la cible\n",
    "features = [col for col in liste_variables_explicatives]\n",
    "X = result_train[features]\n",
    "y = result_train[\"debit\"]\n",
    "\n",
    "# Division entre l'ensemble train et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Création des poids d'échantillon : 5 pour LAT et LON, 1 pour les autres\n",
    "sample_weights_train = [100 if (row['LAT'] != 0 and row['LON'] != 0) else 1 for _, row in X_train.iterrows()]\n",
    "\n",
    "# Entrainement du modèle avec les poids d'échantillon\n",
    "model = XGBRegressor(\n",
    "    n_estimators=200,  # Nombre d'arbres\n",
    "    learning_rate=0.1,  # Taux d'apprentissage\n",
    "    max_depth=15,  # Profondeur maximale des arbres\n",
    "    subsample=0.8,  # Fraction d'échantillons pour chaque arbre\n",
    "    colsample_bytree=0.8,  # Fraction de colonnes utilisées par arbre\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Utilisez les poids corrects (sample_weights_train)\n",
    "model.fit(X_train, y_train, sample_weight=sample_weights_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluer le modèle\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8cbb23",
   "metadata": {},
   "source": [
    "On obtient un R² proche de 1 et une mean square error a relativiser (entre 10 et 30 selon les exécutions), ce qui est assez satisfaisant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28102e4f",
   "metadata": {},
   "source": [
    "## 3.4 Prédiction\n",
    "\n",
    "Notre modèle est voué à être utilisé par les membres des clubs d'aviron, donc les prédictions sont ajustables.\n",
    "On demande à l'utilisateur du service de rentrer la date pour laquelle il souhaite avoir une prédiction du débit, ainsi que les conditions du bassin qu'il souhaite consulter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a44c25",
   "metadata": {},
   "source": [
    "On récupère toutes les données qui vont permettre de faire la prédiction grâce à cette entrée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33957083",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# On demande à l'utilisateur de rentrer la date et l'heure sous la forme dd/MM/yyyy HH:mm et le nom du club\n",
    "date_str = input(\"Vous souhaitez connaitre le débit dans les quelques prochains jours sur un bassin de long de la Seine ? Entrez la date et l'heure sous la forme dd/MM/yyyy HH:mm : \")\n",
    "club = input(\"Entrez le nom du club d'aviron : \")\n",
    "\n",
    "# Conversion de la chaîne de caractères en objet datetime\n",
    "try:\n",
    "    # L'entrée est bien une chaîne de caractères et la convertir en objet datetime\n",
    "    date = datetime.strptime(date_str, \"%d/%m/%Y %H:%M\")\n",
    "    \n",
    "    # Extraction du jour, le mois, l'année, l'heure et les minutes\n",
    "    day = date.day\n",
    "    month = date.month\n",
    "    year = date.year\n",
    "    hour = date.hour\n",
    "    minute = date.minute\n",
    "    \n",
    "    # Résultats\n",
    "    print(f\"Date et heure entrée : {date.strftime('%d-%m-%Y %H:%M')}\")\n",
    "\n",
    "    \n",
    "except ValueError:\n",
    "    print(\"La date et l'heure entrées sont invalides. Veuillez entrer la date au format dd/MM/yyyy HH:mm.\")\n",
    "\n",
    "# Vérifier si le club est dans la colonne \"Club\" du DataFrame\n",
    "if club in clubs_hydro_meteo[\"Club\"].values:\n",
    "    print(f\"Club d'aviron sélectionné : {club}\")\n",
    "else:\n",
    "    # Afficher un message si le club n'est pas reconnu\n",
    "    clubs_list = \", \".join(clubs_hydro_meteo[\"Club\"].values)\n",
    "    print(f\"Le club n'est pas reconnu. Merci de choisir un club parmi : {clubs_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76891f83",
   "metadata": {},
   "source": [
    "On construit le dataframe qui nous servira de base pour la prédiction liée à ce club et à son bassin en particulier, en téléchargeant via l'API d'hydro.eaufrance les données de débit des 30 derniers jours à la station hydrométrique la plus proche, et en récupérant les données météo de la station météo la plus proche pour la même période."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7990da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Station hydrométrique la plus proche du club recherché\n",
    "recherche = clubs_hydro_meteo[clubs_hydro_meteo['Club'].str.contains(club, case=False, na=False)]\n",
    "\n",
    "# Afficher le NUM_NHS ou un message d'erreur\n",
    "NUM_NHS_predict=recherche['NUM_NHS'].values[0] if not recherche.empty else \"Club non trouvé.\"\n",
    "\n",
    "\n",
    "#Période : les 30 derniers jours\n",
    "debut = (datetime.now()-timedelta(30)).isoformat() \n",
    "\n",
    "url_API = \"https://hubeau.eaufrance.fr/api/v1/hydrometrie/observations_tr.csv\"\n",
    "url = url_API+ f\"?code_entite={NUM_NHS_predict}&grandeur_hydro=Q&size=10000&date_debut_obs={debut}\"\n",
    "\n",
    "try :\n",
    "    # Récupération des donnéesen csv et conversaion en dataframe\n",
    "    with urlopen(url) as response:\n",
    "        debit_jours_precedents = pd.read_csv(response, sep=';')\n",
    "\n",
    "    # Normalisation du dataframe\n",
    "    debit_jours_precedents = debit_jours_precedents[['code_station', 'resultat_obs', 'date_obs']]\n",
    "    debit_jours_precedents.rename(columns={\"date_obs\": \"date_heure\", \"resultat_obs\": \"debit\", \"code_station\": \"NUM_NHS\"}, inplace=True)\n",
    "    debit_jours_precedents[\"date_heure\"] = pd.to_datetime(debit_jours_precedents[\"date_heure\"], utc=True).dt.tz_localize(None)  # Conversion date en DateTime\n",
    "    debit_jours_precedents[\"debit\"] = debit_jours_precedents[\"debit\"] / 1000  # Conversion du débit en m³/s (actuellement en l/s)\n",
    "\n",
    "    # Nouvelle colonne pour une valeur arrondie à l'heure pour calculer la moyenne du débit par heure\n",
    "    debit_jours_precedents[\"AAAAMMJJHH\"] = debit_jours_precedents[\"date_heure\"].dt.floor(\"h\")\n",
    "    debit_jours_precedents = debit_jours_precedents.groupby([\"NUM_NHS\", \"AAAAMMJJHH\"], as_index=False)[\"debit\"].mean()\n",
    "\n",
    "    # Affichage du résultat\n",
    "    print(debit_jours_precedents)\n",
    "\n",
    "except Exception as e:\n",
    "    # En cas d'erreur, afficher un message d'erreur\n",
    "    print(\"Une erreur s'est produite lors de l'exécution du programme : \", str(e))\n",
    "    print(\"La station hydrométrique proche de ce club ne fournit pas les données en temps réel.\")\n",
    "    print(\"Nous vous conseillons de regarder le débit pour l'Aviron Club de Villennes-Poissy, à la sortie de Paris.\")\n",
    "    print(\"Si votre club est situé en amont, le débit sera moindre. En aval, il sera plus important.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ef802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: On sélectionne le sous-dataframe de données de débit horaire correspondant\n",
    "debit_club_pred = pd.merge(debit_jours_precedents, clubs_hydro_meteo[['Club', 'LAT', 'LON', 'NUM_NHS', 'NHS']], on='NUM_NHS', how='left')\n",
    "debit_club_pred = debit_club_pred[debit_club_pred['Club'] == club]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57575b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: on joint les données de meteo_horaire_pred avec clubs_hydro_meteo sur NUM_NWS\n",
    "meteo_club_pred = meteo_horaire_pred.merge(\n",
    "    clubs_hydro_meteo[['Club', 'LAT', 'LON', 'NUM_NWS', 'NWS']],\n",
    "    left_on='NUM_POSTE',\n",
    "    right_on='NUM_NWS',\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dac529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: on combine les deux DataFrames sur le Club et la colonne temporelle 'AAAAMJJHH'\n",
    "debit_meteo_combined_pred = debit_club_pred.merge(\n",
    "    meteo_club_pred,\n",
    "    on=['Club', 'AAAAMMJJHH'],\n",
    "    suffixes=('_hydro', '_meteo')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14371ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: on sélectionne les colonnes pertinentes et on copie le dataframe pour éviter les intéractions fâcheuses\n",
    "debit_meteo_combined_predict = debit_meteo_combined_pred[['Club', 'LAT', 'LON','AAAAMMJJHH', 'debit', 'RR1', 'T']].copy()\n",
    "\n",
    "# Et on normalise le dataframe afin de le rendre prêt pour la modélisation\n",
    "# On s'assure que toutes les valeurs sont numériques\n",
    "debit_meteo_combined_predict[\"debit\"] = pd.to_numeric(debit_meteo_combined_predict[\"debit\"], errors=\"coerce\")\n",
    "debit_meteo_combined_predict[\"LAT\"] = pd.to_numeric(debit_meteo_combined_predict[\"LAT\"], errors=\"coerce\")\n",
    "debit_meteo_combined_predict[\"LON\"] = pd.to_numeric(debit_meteo_combined_predict[\"LON\"], errors=\"coerce\")\n",
    "debit_meteo_combined_predict = debit_meteo_combined_predict.dropna(subset=[\"debit\", \"RR1\", \"T\"])\n",
    "\n",
    "# On extrait les caractéristiques temporelles \n",
    "debit_meteo_combined_predict[\"année\"] = debit_meteo_combined_predict[\"AAAAMMJJHH\"].dt.year\n",
    "debit_meteo_combined_predict[\"mois\"] = debit_meteo_combined_predict[\"AAAAMMJJHH\"].dt.month\n",
    "debit_meteo_combined_predict[\"jour\"] = debit_meteo_combined_predict[\"AAAAMMJJHH\"].dt.day\n",
    "debit_meteo_combined_predict[\"heure\"] = debit_meteo_combined_predict[\"AAAAMMJJHH\"].dt.hour\n",
    "\n",
    "# Supprimer la colonne datetime originale si elle n'est plus utile\n",
    "debit_meteo_combined_predict = debit_meteo_combined_predict.drop(columns=[\"AAAAMMJJHH\"])\n",
    "debit_meteo_combined_predict\n",
    "\n",
    "#On ajoute les variables explicatives\n",
    "debit_meteo_combined_predict=create_features(debit_meteo_combined_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40cb601",
   "metadata": {},
   "source": [
    "On peut maintenant procéder à la prédiction : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c04295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On choisit les variables explicatives de meme que dans l'entrainement du modèle\n",
    "features_pred = [col_pred for col_pred in debit_meteo_combined_predict.columns if col_pred not in [\"datetime\", \"Club\", \"debit\"]]\n",
    "X_pred = debit_meteo_combined_predict[features_pred]\n",
    "prediction = model.predict(X_pred)\n",
    "\n",
    "\n",
    "#Resultat\n",
    "resultat_prediction = prediction[0]\n",
    "resultat_prediction = int(resultat_prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571bf97c",
   "metadata": {},
   "source": [
    "Voilà la sortie pour l'utilisateur : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b475ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = f\"Le débit prédit pour le {date} avoisine les {resultat_prediction:.2f} m³/s. \"\n",
    "\n",
    "# Ajout des recommandations en fonction du débit\n",
    "if 550 <= resultat_prediction <= 750:\n",
    "    phrase += (\n",
    "        \"Le débit est assez fort. Nous vous recommandons vivement de ne pas sortir en bateau individuel, pour votre sécurité. \" \n",
    "    )\n",
    "elif resultat_prediction > 750:\n",
    "    phrase += (\n",
    "        \"Attention : le débit est extrêmement élevé. Toute sortie sur l'eau est formellement interdite pour votre sécurité. \" \n",
    "    )\n",
    "else:\n",
    "    phrase += (\n",
    "        \"Les conditions sont idéales ! Vous pouvez profiter sereinement de votre sortie sur l'eau. \"\n",
    "    )\n",
    "\n",
    "# Affichage de la réponse complète\n",
    "display(Markdown(phrase))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac329f0",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Le modèle pourrait être étendu et utilisé par tous les clubs d'aviron, à condition d'une mise à disposition plus aisée de la base des données de débit aux stations hydrométriques. En effet,  data.gouv propose deux manières d'accéder aux données hydrométriques : \n",
    "1. une API accessible par URL, permettant d'avoir accès à toutes les données de débit en France mais uniquement sur les 30 derniers jours\n",
    "2. des archives des données hydrométriques, accessibles uniquement par téléchargement manuel pour chaque station hydrométrique d'intérêt. \n",
    "\n",
    "Afin de ne pas perdre de temps à télécharger des centaines de bases de données hydrométriques nous avons donc choisi de restreindre notre modèle à la Seine. \n",
    "\n",
    "Quelques pistes d'amélioration peuvent être envisagées : trouver le nombre maximal de jours en dessous duquel la prédiction reste à peu près fiable, donner un plus grand poids à la localisation du club d'aviron dans le modèle (tendance à surestimer le débit en amont de la Seine),  créer une vraie interface utilisateur, ou encore affiner notre modèle avec des données géographiques comme les géométries de bassin (reliefs, goulots d'écoulement). Une nuance est à apporter d'ailleurs entre débit et courant : dans le monde de l'aviron, on utilise uniquement de débit, mais pour plus de justesse on devrait utiliser la notion de courant (débit x volume)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
